{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZjySmkiRrEf",
        "outputId": "4f21044b-da6d-45f6-82b6-810bb1f981b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerando dados sintéticos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2994136807.py:10: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  datas = pd.date_range(start=data_inicio, end=data_fim, freq=frequencia)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset gerado: 'dados_vazao_com_volume.csv'\n",
            "                        vazao  volume_acumulado_dia  vazao_futura\n",
            "2025-01-01 00:00:00  0.000000              0.000000      0.554835\n",
            "2025-01-01 00:15:00  0.554835              8.322531      0.008391\n",
            "2025-01-01 00:30:00  0.008391              8.448402      0.000000\n",
            "2025-01-01 00:45:00  0.000000              8.448402      0.000000\n",
            "2025-01-01 01:00:00  0.000000              8.448402      0.000000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_inicio = \"2025-01-01 00:00:00\"\n",
        "data_fim = \"2025-06-01 00:00:00\"\n",
        "frequencia = \"15T\" # 15 minutos\n",
        "\n",
        "print(\"Gerando dados sintéticos...\")\n",
        "datas = pd.date_range(start=data_inicio, end=data_fim, freq=frequencia)\n",
        "df = pd.DataFrame(index=datas)\n",
        "\n",
        "df['vazao'] = 0.2\n",
        "perfil_diario = {\n",
        "    0:0.1, 1:0.1, 2:0.1, 3:0.1, 4:0.2, 5:1.0,\n",
        "    6:8.0, 7:15.0, 8:10.0, 9:5.0, 10:4.0, 11:7.0,\n",
        "    12:12.0, 13:10.0, 14:4.0, 15:3.0, 16:3.0, 17:5.0,\n",
        "    18:10.0, 19:18.0, 20:15.0, 21:8.0, 22:4.0, 23:1.0\n",
        "}\n",
        "perfil_semanal = {0:1.0, 1:1.0, 2:1.05, 3:1.0, 4:0.95, 5:1.2, 6:1.15}\n",
        "\n",
        "horas = df.index.hour\n",
        "dias_semana = df.index.dayofweek\n",
        "\n",
        "df['vazao'] += (horas.map(perfil_diario) * dias_semana.map(perfil_semanal))\n",
        "df['vazao'] += np.random.normal(0, 0.5, len(df)) # Ruído\n",
        "df['vazao'] = df['vazao'].clip(lower=0) # Sem vazão negativa\n",
        "\n",
        "df['volume_intervalo'] = df['vazao'] * 15.0\n",
        "\n",
        "\n",
        "df['volume_acumulado_dia'] = df.groupby(df.index.date)['volume_intervalo'].cumsum()\n",
        "\n",
        "df['vazao_futura'] = df['vazao'].shift(-1)\n",
        "\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df.to_csv('dados_vazao.csv')\n",
        "print(\"Dataset gerado: 'dados_vazao_com_volume.csv'\")\n",
        "print(df[['vazao', 'volume_acumulado_dia', 'vazao_futura']].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "df = pd.read_csv('/content/dados_vazao.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "df['hora'] = df.index.hour\n",
        "df['dia_semana'] = df.index.dayofweek\n",
        "\n",
        "features = ['hora', 'dia_semana', 'vazao', 'volume_acumulado_dia']\n",
        "target = 'vazao_futura'\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "print(\"\\n--- COPIE ISTO PARA O C++ ---\")\n",
        "print(f\"const float X_min[4] = {{ {', '.join([f'{x:.6f}' for x in scaler_X.data_min_])} }};\")\n",
        "print(f\"const float X_scale[4] = {{ {', '.join([f'{x:.6f}' for x in scaler_X.scale_])} }};\")\n",
        "print(f\"const float y_min = {scaler_y.data_min_[0]:.6f};\")\n",
        "print(f\"const float y_scale = {scaler_y.scale_[0]:.6f};\")\n",
        "print(\"-----------------------------\\n\")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=[4]), # 4 Entradas\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1) # 1 Saída (Previsão)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nErro Médio Absoluto (Normalizado): {mae:.4f}\")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('modelo_vazao_v2.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Modelo salvo: 'modelo_vazao.tflite'\")\n",
        "print(\"Não esqueça de rodar: xxd -i modelo_vazao_v2.tflite > modelo_vazao.h\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzfnFD-YS-Tw",
        "outputId": "959785f8-2756-4a0f-a966-692dd45992f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- COPIE ISTO PARA O C++ ---\n",
            "const float X_min[4] = { 0.000000, 0.000000, 0.000000, 0.000000 };\n",
            "const float X_scale[4] = { 0.043478, 0.166667, 0.043631, 0.000093 };\n",
            "const float y_min = 0.000000;\n",
            "const float y_scale = 0.043631;\n",
            "-----------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0140 - mae: 0.0818\n",
            "Epoch 2/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0567\n",
            "Epoch 3/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0584\n",
            "Epoch 4/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0564\n",
            "Epoch 5/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 - mae: 0.0581\n",
            "Epoch 6/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0571\n",
            "Epoch 7/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0566\n",
            "Epoch 8/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0583\n",
            "Epoch 9/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0586\n",
            "Epoch 10/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0579\n",
            "Epoch 11/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0583\n",
            "Epoch 12/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0081 - mae: 0.0581\n",
            "Epoch 13/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0080 - mae: 0.0578\n",
            "Epoch 14/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0582\n",
            "Epoch 15/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0581\n",
            "Epoch 16/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0578\n",
            "Epoch 17/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0576\n",
            "Epoch 18/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0584\n",
            "Epoch 19/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0081 - mae: 0.0577\n",
            "Epoch 20/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 - mae: 0.0590\n",
            "Epoch 21/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0584\n",
            "Epoch 22/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0570\n",
            "Epoch 23/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 - mae: 0.0587\n",
            "Epoch 24/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0583\n",
            "Epoch 25/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0566\n",
            "Epoch 26/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0570\n",
            "Epoch 27/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0570\n",
            "Epoch 28/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0575\n",
            "Epoch 29/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0566\n",
            "Epoch 30/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0581\n",
            "Epoch 31/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0575\n",
            "Epoch 32/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0584\n",
            "Epoch 33/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0576\n",
            "Epoch 34/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0583\n",
            "Epoch 35/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0079 - mae: 0.0580\n",
            "Epoch 36/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0079 - mae: 0.0584\n",
            "Epoch 37/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0573\n",
            "Epoch 38/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0583\n",
            "Epoch 39/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0580\n",
            "Epoch 40/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0580\n",
            "Epoch 41/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0579\n",
            "Epoch 42/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0588\n",
            "Epoch 43/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0583\n",
            "Epoch 44/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0568\n",
            "Epoch 45/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0572\n",
            "Epoch 46/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0589\n",
            "Epoch 47/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0582\n",
            "Epoch 48/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0589\n",
            "Epoch 49/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0578\n",
            "Epoch 50/50\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0580\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mae: 0.0548\n",
            "\n",
            "Erro Médio Absoluto (Normalizado): 0.0555\n",
            "Saved artifact at '/tmp/tmp2iv1nmtz'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 4), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132623250587280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132623250586896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132623244953552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132623244953936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132623244953360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132623244952400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Modelo salvo: 'modelo_vazao_v2.tflite'\n",
            "Não esqueça de rodar: xxd -i modelo_vazao_v2.tflite > modelo_vazao.h\n"
          ]
        }
      ]
    }
  ]
}